{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sınıflandırma Tabanlı Anomali Tespiti\n",
    "\n",
    "Bu notebook, KDD Cup 1999 veri seti üzerinde supervised learning yöntemleri kullanarak anomali tespiti gerçekleştirir.\n",
    "\n",
    "## Kullanılan Yöntemler:\n",
    "- **Random Forest**: Ensemble tabanlı sınıflandırma\n",
    "- **Gradient Boosting**: Boosting tabanlı güçlü sınıflandırıcı\n",
    "- **Support Vector Machine**: Kernel tabanlı sınıflandırma\n",
    "- **Neural Network**: Derin öğrenme yaklaşımı\n",
    "- **Logistic Regression**: Basit ve hızlı linear model\n",
    "- **Naive Bayes**: Probabilistik sınıflandırıcı\n",
    "\n",
    "## Hedefler:\n",
    "1. Farklı sınıflandırma algoritmalarını karşılaştırmak\n",
    "2. Özellik önemlerini analiz etmek\n",
    "3. Confusion matrix ve classification report ile detaylı analiz\n",
    "4. ROC eğrileri ve AUC skorları ile performans değerlendirmesi\n",
    "5. Saldırı türlerine göre performans analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri import et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Görselleştirme ayarları\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veri Yükleme ve Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yükleme\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data import load_kdd_data\n",
    "\n",
    "# Veriyi yükle\n",
    "print(\"Veri yükleniyor...\")\n",
    "X_train, X_test, y_train, y_test = load_kdd_data()\n",
    "\n",
    "print(f\"Eğitim seti boyutu: {X_train.shape}\")\n",
    "print(f\"Test seti boyutu: {X_test.shape}\")\n",
    "\n",
    "# Binary etiketler oluştur (0: normal, 1: anomali)\n",
    "y_train_binary = (y_train != 'normal').astype(int)\n",
    "y_test_binary = (y_test != 'normal').astype(int)\n",
    "\n",
    "print(f\"Eğitim setinde normal: {sum(y_train_binary == 0)}, anomali: {sum(y_train_binary == 1)}\")\n",
    "print(f\"Test setinde normal: {sum(y_test_binary == 0)}, anomali: {sum(y_test_binary == 1)}\")\n",
    "\n",
    "# Saldırı türlerini analiz et\n",
    "print(\"\\nSaldırı türleri:\")\n",
    "attack_counts = y_train.value_counts()\n",
    "print(attack_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri ön işleme\n",
    "print(\"Veri ön işleme yapılıyor...\")\n",
    "\n",
    "# Kategorik değişkenleri encode et\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "\n",
    "# Label encoding\n",
    "le_dict = {}\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Tüm benzersiz değerleri birleştir\n",
    "    all_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
    "    le.fit(all_values)\n",
    "    \n",
    "    X_train_encoded[col] = le.transform(X_train[col])\n",
    "    X_test_encoded[col] = le.transform(X_test[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "print(\"Kategorik değişkenler encode edildi.\")\n",
    "\n",
    "# Sabit kolonları kaldır\n",
    "constant_cols = X_train_encoded.columns[X_train_encoded.nunique() <= 1]\n",
    "if len(constant_cols) > 0:\n",
    "    print(f\"Sabit kolonlar kaldırılıyor: {list(constant_cols)}\")\n",
    "    X_train_encoded = X_train_encoded.drop(columns=constant_cols)\n",
    "    X_test_encoded = X_test_encoded.drop(columns=constant_cols)\n",
    "\n",
    "print(f\"İşlenmiş veri boyutu: {X_train_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi normalize et\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "print(\"Veri normalizasyonu tamamlandı.\")\n",
    "\n",
    "# Performans için küçük bir subset kullan\n",
    "np.random.seed(42)\n",
    "train_sample_size = min(50000, len(X_train_scaled))\n",
    "test_sample_size = min(20000, len(X_test_scaled))\n",
    "\n",
    "train_indices = np.random.choice(len(X_train_scaled), train_sample_size, replace=False)\n",
    "test_indices = np.random.choice(len(X_test_scaled), test_sample_size, replace=False)\n",
    "\n",
    "X_train_sample = X_train_scaled[train_indices]\n",
    "y_train_sample = y_train_binary.iloc[train_indices]\n",
    "X_test_sample = X_test_scaled[test_indices]\n",
    "y_test_sample = y_test_binary.iloc[test_indices]\n",
    "\n",
    "print(f\"Eğitim sample boyutu: {X_train_sample.shape}\")\n",
    "print(f\"Test sample boyutu: {X_test_sample.shape}\")\n",
    "print(f\"Sample'da normal/anomali oranı: {sum(y_train_sample == 0)}/{sum(y_train_sample == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Analizi ve Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf dağılımını görselleştir\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Binary sınıf dağılımı\n",
    "binary_counts = y_train_sample.value_counts()\n",
    "axes[0].pie(binary_counts.values, labels=['Normal', 'Anomali'], autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Binary Sınıf Dağılımı (Eğitim Seti)')\n",
    "\n",
    "# Saldırı türleri dağılımı (orijinal etiketler)\n",
    "y_train_orig_sample = y_train.iloc[train_indices]\n",
    "attack_counts_sample = y_train_orig_sample.value_counts().head(10)\n",
    "axes[1].bar(range(len(attack_counts_sample)), attack_counts_sample.values)\n",
    "axes[1].set_xticks(range(len(attack_counts_sample)))\n",
    "axes[1].set_xticklabels(attack_counts_sample.index, rotation=45, ha='right')\n",
    "axes[1].set_title('En Yaygın Saldırı Türleri')\n",
    "axes[1].set_ylabel('Sayı')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA ile boyut azaltma ve görselleştirme\n",
    "print(\"PCA ile boyut azaltma yapılıyor...\")\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_sample[:5000])  # Hız için subset\n",
    "y_train_pca = y_train_sample.iloc[:5000]\n",
    "\n",
    "print(f\"PCA açıklanan varyans oranı: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Toplam açıklanan varyans: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# PCA sonuçlarını görselleştir\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_train_pca[y_train_pca == 0, 0], X_train_pca[y_train_pca == 0, 1], \n",
    "                     alpha=0.6, label='Normal', s=20)\n",
    "plt.scatter(X_train_pca[y_train_pca == 1, 0], X_train_pca[y_train_pca == 1, 1], \n",
    "           alpha=0.6, label='Anomali', s=20)\n",
    "plt.title('PCA - Veri Dağılımı (Normal vs Anomali)')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varyans)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varyans)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Eğitimi ve Değerlendirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelleri tanımla\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"Modeller eğitiliyor...\")\n",
    "\n",
    "# Model sonuçlarını sakla\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} eğitiliyor...\")\n",
    "    \n",
    "    # Modeli eğit\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    \n",
    "    # Tahminler\n",
    "    y_pred = model.predict(X_test_sample)\n",
    "    y_pred_proba = model.predict_proba(X_test_sample)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sample)\n",
    "    \n",
    "    # Metrikleri hesapla\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_sample, y_pred)\n",
    "    precision = precision_score(y_test_sample, y_pred)\n",
    "    recall = recall_score(y_test_sample, y_pred)\n",
    "    f1 = f1_score(y_test_sample, y_pred)\n",
    "    \n",
    "    # ROC AUC\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_test_sample, y_pred_proba)\n",
    "    except:\n",
    "        roc_auc = 0.5\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   F1-Score: {f1:.3f}\")\n",
    "    print(f\"   ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "print(\"\\nTüm modeller eğitildi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performans Karşılaştırması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları DataFrame'e çevir\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.drop(columns=['predictions', 'probabilities'])\n",
    "\n",
    "print(\"=== MODEL PERFORMANS KARSILASTIRMASI ===\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# En iyi modelleri belirle\n",
    "best_f1 = results_df['f1_score'].idxmax()\n",
    "best_auc = results_df['roc_auc'].idxmax()\n",
    "best_accuracy = results_df['accuracy'].idxmax()\n",
    "\n",
    "print(f\"\\nEn iyi F1-Score: {best_f1} ({results_df.loc[best_f1, 'f1_score']:.3f})\")\n",
    "print(f\"En iyi ROC-AUC: {best_auc} ({results_df.loc[best_auc, 'roc_auc']:.3f})\")\n",
    "print(f\"En iyi Accuracy: {best_accuracy} ({results_df.loc[best_accuracy, 'accuracy']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performans metrikleri görselleştirmesi\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    values = results_df[metric].values\n",
    "    model_names = results_df.index\n",
    "    \n",
    "    bars = ax.bar(range(len(model_names)), values, alpha=0.8)\n",
    "    ax.set_title(f'{name} Karşılaştırması')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_xticks(range(len(model_names)))\n",
    "    ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Değerleri bar üzerine yaz\n",
    "    for bar, value in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ROC Eğrileri ve AUC Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC eğrileri\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown']\n",
    "\n",
    "for i, (name, color) in enumerate(zip(results.keys(), colors)):\n",
    "    y_pred_proba = results[name]['probabilities']\n",
    "    \n",
    "    # ROC eğrisi hesapla\n",
    "    fpr, tpr, _ = roc_curve(y_test_sample, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=color, lw=2, \n",
    "             label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Diagonal çizgi (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.5, label='Random (AUC = 0.500)')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Eğrileri Karşılaştırması')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall eğrileri\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, (name, color) in enumerate(zip(results.keys(), colors)):\n",
    "    y_pred_proba = results[name]['probabilities']\n",
    "    \n",
    "    # Precision-Recall eğrisi hesapla\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test_sample, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_test_sample, y_pred_proba)\n",
    "    \n",
    "    plt.plot(recall_curve, precision_curve, color=color, lw=2, \n",
    "             label=f'{name} (AP = {avg_precision:.3f})')\n",
    "\n",
    "# Baseline (random classifier)\n",
    "baseline = sum(y_test_sample) / len(y_test_sample)\n",
    "plt.axhline(y=baseline, color='k', linestyle='--', alpha=0.5, \n",
    "            label=f'Random (AP = {baseline:.3f})')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Eğrileri Karşılaştırması')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi 4 modelin confusion matrix'ini göster\n",
    "top_models = results_df.nlargest(4, 'f1_score').index\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, model_name in enumerate(top_models):\n",
    "    y_pred = results[model_name]['predictions']\n",
    "    cm = confusion_matrix(y_test_sample, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f'{model_name}\\nF1: {results[model_name][\"f1_score\"]:.3f}, AUC: {results[model_name][\"roc_auc\"]:.3f}')\n",
    "    axes[i].set_xlabel('Tahmin Edilen')\n",
    "    axes[i].set_ylabel('Gerçek')\n",
    "    axes[i].set_xticklabels(['Normal', 'Anomali'])\n",
    "    axes[i].set_yticklabels(['Normal', 'Anomali'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Özellik Önemleri Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest ve Gradient Boosting için özellik önemleri\n",
    "feature_names = X_train_encoded.columns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Random Forest\n",
    "if 'Random Forest' in trained_models:\n",
    "    rf_model = trained_models['Random Forest']\n",
    "    rf_importance = rf_model.feature_importances_\n",
    "    \n",
    "    # En önemli 15 özelliği al\n",
    "    top_indices = np.argsort(rf_importance)[-15:]\n",
    "    \n",
    "    axes[0].barh(range(len(top_indices)), rf_importance[top_indices])\n",
    "    axes[0].set_yticks(range(len(top_indices)))\n",
    "    axes[0].set_yticklabels([feature_names[i] for i in top_indices])\n",
    "    axes[0].set_title('Random Forest - En Önemli Özellikler')\n",
    "    axes[0].set_xlabel('Önem Skoru')\n",
    "\n",
    "# Gradient Boosting\n",
    "if 'Gradient Boosting' in trained_models:\n",
    "    gb_model = trained_models['Gradient Boosting']\n",
    "    gb_importance = gb_model.feature_importances_\n",
    "    \n",
    "    # En önemli 15 özelliği al\n",
    "    top_indices = np.argsort(gb_importance)[-15:]\n",
    "    \n",
    "    axes[1].barh(range(len(top_indices)), gb_importance[top_indices])\n",
    "    axes[1].set_yticks(range(len(top_indices)))\n",
    "    axes[1].set_yticklabels([feature_names[i] for i in top_indices])\n",
    "    axes[1].set_title('Gradient Boosting - En Önemli Özellikler')\n",
    "    axes[1].set_xlabel('Önem Skoru')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression katsayıları\n",
    "if 'Logistic Regression' in trained_models:\n",
    "    lr_model = trained_models['Logistic Regression']\n",
    "    lr_coef = lr_model.coef_[0]\n",
    "    \n",
    "    # En yüksek mutlak katsayılara sahip özellikleri al\n",
    "    abs_coef = np.abs(lr_coef)\n",
    "    top_indices = np.argsort(abs_coef)[-15:]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = ['red' if coef < 0 else 'blue' for coef in lr_coef[top_indices]]\n",
    "    plt.barh(range(len(top_indices)), lr_coef[top_indices], color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(top_indices)), [feature_names[i] for i in top_indices])\n",
    "    plt.title('Logistic Regression - Özellik Katsayıları')\n",
    "    plt.xlabel('Katsayı Değeri')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='blue', alpha=0.7, label='Pozitif (Anomali yönünde)'),\n",
    "                      Patch(facecolor='red', alpha=0.7, label='Negatif (Normal yönünde)')]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Saldırı Türlerine Göre Performans Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modeli seç\n",
    "best_model_name = results_df['f1_score'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"En iyi model: {best_model_name}\")\n",
    "\n",
    "# Test setindeki saldırı türlerini analiz et\n",
    "y_test_orig_sample = y_test.iloc[test_indices]\n",
    "y_pred_best = results[best_model_name]['predictions']\n",
    "\n",
    "# Saldırı türlerine göre performans\n",
    "attack_types = y_test_orig_sample.unique()\n",
    "attack_performance = {}\n",
    "\n",
    "for attack_type in attack_types:\n",
    "    mask = y_test_orig_sample == attack_type\n",
    "    if sum(mask) > 10:  # En az 10 örnek olsun\n",
    "        y_true_attack = y_test_sample[mask]\n",
    "        y_pred_attack = y_pred_best[mask]\n",
    "        \n",
    "        if attack_type == 'normal':\n",
    "            # Normal için specificity (true negative rate)\n",
    "            tn = sum((y_true_attack == 0) & (y_pred_attack == 0))\n",
    "            fp = sum((y_true_attack == 0) & (y_pred_attack == 1))\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            attack_performance[attack_type] = {\n",
    "                'count': sum(mask),\n",
    "                'specificity': specificity,\n",
    "                'accuracy': accuracy_score(y_true_attack, y_pred_attack)\n",
    "            }\n",
    "        else:\n",
    "            # Anomali türleri için sensitivity (recall)\n",
    "            tp = sum((y_true_attack == 1) & (y_pred_attack == 1))\n",
    "            fn = sum((y_true_attack == 1) & (y_pred_attack == 0))\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            attack_performance[attack_type] = {\n",
    "                'count': sum(mask),\n",
    "                'sensitivity': sensitivity,\n",
    "                'accuracy': accuracy_score(y_true_attack, y_pred_attack)\n",
    "            }\n",
    "\n",
    "# Sonuçları göster\n",
    "print(\"\\n=== SALDIRI TÜRLERİNE GÖRE PERFORMANS ===")\n",
    "for attack_type, perf in attack_performance.items():\n",
    "    print(f\"\\n{attack_type}:\")\n",
    "    print(f\"  Örnek sayısı: {perf['count']}\")\n",
    "    print(f\"  Accuracy: {perf['accuracy']:.3f}\")\n",
    "    if 'sensitivity' in perf:\n",
    "        print(f\"  Sensitivity (Recall): {perf['sensitivity']:.3f}\")\n",
    "    if 'specificity' in perf:\n",
    "        print(f\"  Specificity: {perf['specificity']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saldırı türlerine göre performansı görselleştir\n",
    "attack_names = []\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "counts = []\n",
    "\n",
    "for attack_type, perf in attack_performance.items():\n",
    "    if attack_type != 'normal':  # Normal hariç\n",
    "        attack_names.append(attack_type)\n",
    "        accuracies.append(perf['accuracy'])\n",
    "        sensitivities.append(perf.get('sensitivity', 0))\n",
    "        counts.append(perf['count'])\n",
    "\n",
    "if len(attack_names) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].bar(range(len(attack_names)), accuracies, alpha=0.7)\n",
    "    axes[0].set_xticks(range(len(attack_names)))\n",
    "    axes[0].set_xticklabels(attack_names, rotation=45, ha='right')\n",
    "    axes[0].set_title('Saldırı Türlerine Göre Accuracy')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Sensitivity (Recall)\n",
    "    axes[1].bar(range(len(attack_names)), sensitivities, alpha=0.7, color='orange')\n",
    "    axes[1].set_xticks(range(len(attack_names)))\n",
    "    axes[1].set_xticklabels(attack_names, rotation=45, ha='right')\n",
    "    axes[1].set_title('Saldırı Türlerine Göre Sensitivity (Recall)')\n",
    "    axes[1].set_ylabel('Sensitivity')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Karşılaştırması ve Sonuçlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kapsamlı model karşılaştırması\n",
    "print(\"\\n=== KAPSAMLI MODEL KARŞILAŞTIRMASI ===")\n",
    "\n",
    "# Sıralama\n",
    "results_df_sorted = results_df.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"F1-Score'a göre sıralama:\")\n",
    "for i, (model, row) in enumerate(results_df_sorted.iterrows(), 1):\n",
    "    print(f\"{i}. {model}:\")\n",
    "    print(f\"   F1-Score: {row['f1_score']:.3f}\")\n",
    "    print(f\"   ROC-AUC: {row['roc_auc']:.3f}\")\n",
    "    print(f\"   Accuracy: {row['accuracy']:.3f}\")\n",
    "    print(f\"   Precision: {row['precision']:.3f}\")\n",
    "    print(f\"   Recall: {row['recall']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart ile model karşılaştırması\n",
    "import math\n",
    "\n",
    "# En iyi 4 modeli seç\n",
    "top_4_models = results_df.nlargest(4, 'f1_score')\n",
    "\n",
    "# Radar chart için veri hazırla\n",
    "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Açıları hesapla\n",
    "angles = [n / float(len(categories)) * 2 * math.pi for n in range(len(categories))]\n",
    "angles += angles[:1]  # Döngüyü kapat\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "for i, (model_name, row) in enumerate(top_4_models.iterrows()):\n",
    "    values = [row['accuracy'], row['precision'], row['recall'], row['f1_score'], row['roc_auc']]\n",
    "    values += values[:1]  # Döngüyü kapat\n",
    "    \n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors[i])\n",
    "    ax.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "\n",
    "# Kategori etiketlerini ekle\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Model Performans Karşılaştırması (Radar Chart)', size=16, y=1.1)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sonuçlar ve Öneriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sonuçları ve öneriler\n",
    "print(\"\\n=== SONUÇLAR VE ÖNERİLER ===")\n",
    "\n",
    "best_model_name = results_df['f1_score'].idxmax()\n",
    "best_model_scores = results_df.loc[best_model_name]\n",
    "\n",
    "print(f\"1. EN İYİ MODEL: {best_model_name}\")\n",
    "print(f\"   • F1-Score: {best_model_scores['f1_score']:.3f}\")\n",
    "print(f\"   • ROC-AUC: {best_model_scores['roc_auc']:.3f}\")\n",
    "print(f\"   • Accuracy: {best_model_scores['accuracy']:.3f}\")\n",
    "print(f\"   • Precision: {best_model_scores['precision']:.3f}\")\n",
    "print(f\"   • Recall: {best_model_scores['recall']:.3f}\")\n",
    "\n",
    "print(\"2. MODEL ÖZELLİKLERİ:\")\n",
    "for model_name in results_df.index:\n",
    "    if model_name == 'Random Forest':\n",
    "        print(\"   • Random Forest: Hızlı, yorumlanabilir, overfitting'e dirençli\")\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        print(\"   • Gradient Boosting: Güçlü, yavaş, hiperparametre hassas\")\n",
    "    elif model_name == 'SVM':\n",
    "        print(\"   • SVM: Güçlü, yavaş, kernel seçimi önemli\")\n",
    "    elif model_name == 'Neural Network':\n",
    "        print(\"   • Neural Network: Esnek, karmaşık, eğitim süresi uzun\")\n",
    "    elif model_name == 'Logistic Regression':\n",
    "        print(\"   • Logistic Regression: Hızlı, basit, yorumlanabilir\")\n",
    "    elif model_name == 'Naive Bayes':\n",
    "        print(\"   • Naive Bayes: Çok hızlı, basit, özellik bağımsızlığı varsayımı\")\n",
    "\n",
    "print(\"3. ÖNERİLER:\")\n",
    "if best_model_scores['f1_score'] > 0.9:\n",
    "    print(\"   ✓ Mükemmel performans! Model production'a hazır.\")\n",
    "elif best_model_scores['f1_score'] > 0.8:\n",
    "    print(\"   ✓ İyi performans. Hiperparametre optimizasyonu ile iyileştirilebilir.\")\n",
    "elif best_model_scores['f1_score'] > 0.7:\n",
    "    print(\"   ⚠ Orta performans. Özellik mühendisliği ve model tuning gerekli.\")\n",
    "else:\n",
    "    print(\"   ❌ Düşük performans. Veri ön işleme ve model seçimi gözden geçirilmeli.\")\n",
    "\n",
    "print(\"4. GELİŞTİRME ÖNERİLERİ:\")\n",
    "print(\"   • Hiperparametre optimizasyonu (GridSearchCV, RandomizedSearchCV)\")\n",
    "print(\"   • Özellik seçimi ve mühendisliği\")\n",
    "print(\"   • Ensemble yöntemleri (Voting, Stacking)\")\n",
    "print(\"   • Çapraz doğrulama ile daha güvenilir değerlendirme\")\n",
    "print(\"   • Daha fazla veri ile eğitim\")\n",
    "print(\"   • Sınıf dengesizliği için SMOTE, class_weight ayarları\")\n",
    "print(\"   • Deep learning modelleri (CNN, LSTM) deneme\")"
   ]
  }
 ]
}